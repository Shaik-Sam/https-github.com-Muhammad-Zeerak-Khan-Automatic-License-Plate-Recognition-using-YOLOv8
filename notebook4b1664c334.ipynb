{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8006423,"sourceType":"datasetVersion","datasetId":4715464},{"sourceId":8834237,"sourceType":"datasetVersion","datasetId":5316004},{"sourceId":8843204,"sourceType":"datasetVersion","datasetId":5322424}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n\n# How to Train YOLOv10 Object Detection on a Custom Dataset\n\n---\n\n[![arXiv](https://img.shields.io/badge/arXiv-2405.14458-b31b1b.svg)](https://arxiv.org/pdf/2405.14458.pdf)\n[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/THU-MIG/yolov10)\n[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/SkalskiP/YOLO-ARENA)\n\nYOLOv10 is a new generation in the YOLO series for real-time end-to-end object detection. It aims to improve both the performance and efficiency of YOLOs by eliminating the need for non-maximum suppression (NMS) and optimizing model architecture comprehensively. This advancement reduces computational overhead, enhancing both efficiency and capability. YOLOv10 shows state-of-the-art performance and efficiency, with YOLOv10-S being 1.8 times faster than RT-DETR-R18 and having significantly fewer parameters and FLOPs. Additionally, YOLOv10-B demonstrates 46% less latency and 25% fewer parameters compared to YOLOv9-C while maintaining the same performance.\n\n<p align=\"center\">\n  <img src=\"https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/yolov10_latency.svg\" width=48%>\n  <img src=\"https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/yolov10_params.svg\" width=48%> <br>\n  Comparisons with others in terms of latency-accuracy (left) and size-accuracy (right) trade-offs.\n</p>\n\n## Pro Tip: Use GPU Acceleration\n\nIf you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n\n## Steps in this Tutorial\n\nIn this tutorial, we are going to cover:\n\n- Before you start\n- Install YOLOv10\n- Download pre-trained weights\n- Download example data\n- Inference with Pre-trained COCO Model\n- Download dataset from Roboflow Universe\n- Custom Training\n- Validate Custom Model\n- Inference with Custom Model\n\n**Let's begin!**","metadata":{"id":"oe9vkEvFABbN"}},{"cell_type":"markdown","source":"## Before you start\n\nLet's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.","metadata":{"id":"FyRdDYkqAKN4"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8cDtxLIBHgQ","outputId":"f4d7f4b6-9cf8-4e85-c173-b435642a570f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjpPg4mGKc1v","outputId":"9311d67a-2c89-4bab-f16d-a481cb470be7","execution":{"iopub.status.busy":"2024-07-02T17:08:26.960747Z","iopub.execute_input":"2024-07-02T17:08:26.961651Z","iopub.status.idle":"2024-07-02T17:08:26.966673Z","shell.execute_reply.started":"2024-07-02T17:08:26.961604Z","shell.execute_reply":"2024-07-02T17:08:26.965698Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Install YOLOv10","metadata":{"id":"3C3EO_2zNChu"}},{"cell_type":"markdown","source":"**NOTE:** Currently, YOLOv10 does not have its own PyPI package. Therefore, we need to install the code from the source.","metadata":{"id":"eBrlDQHUo_M5"}},{"cell_type":"code","source":"!pip install -q git+https://github.com/THU-MIG/yolov10.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdSMcABDNKW-","outputId":"c80e35a5-3055-4bf1-d65b-bbd5f75a5594","execution":{"iopub.status.busy":"2024-07-02T17:06:33.266164Z","iopub.execute_input":"2024-07-02T17:06:33.267049Z","iopub.status.idle":"2024-07-02T17:07:00.579995Z","shell.execute_reply.started":"2024-07-02T17:06:33.267009Z","shell.execute_reply":"2024-07-02T17:07:00.578728Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/abewley/sort.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** We will also install two additional packages: [`roboflow`](https://github.com/roboflow/roboflow-python) to download the dataset from [Roboflow Universe](https://universe.roboflow.com/), which we will use to train our model, and [`supervision`](https://github.com/roboflow/supervision), which we will use for visualizing the results.","metadata":{"id":"Szn2UQBxqxnR"}},{"cell_type":"code","source":"!pip install -q supervision roboflow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bf6A7E9glExI","outputId":"a388e072-0a12-4577-8cd1-0bf50bd2a6f0","execution":{"iopub.status.busy":"2024-07-02T17:08:35.063269Z","iopub.execute_input":"2024-07-02T17:08:35.064146Z","iopub.status.idle":"2024-07-02T17:08:47.595639Z","shell.execute_reply.started":"2024-07-02T17:08:35.064111Z","shell.execute_reply":"2024-07-02T17:08:47.594288Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Download pre-trained weights","metadata":{"id":"JMEtcxdshoEC"}},{"cell_type":"markdown","source":"**NOTE:** YOLOv10 provides weight files pre-trained on the COCO dataset in various sizes. Let's download them.","metadata":{"id":"CF1nAW3Dri83"}},{"cell_type":"code","source":"!mkdir -p {HOME}/weights\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10s.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10m.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10b.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10x.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10l.pt\n!ls -lh {HOME}/weights","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2l67kw8xiYPX","outputId":"623d812e-d462-4346-c992-0218854b52e9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download example data\n\n**NONE:** Let's download few example images. Feel free to use your images or videos.","metadata":{"id":"QGXXr46SlXrr"}},{"cell_type":"code","source":"# !mkdir -p {HOME}/data\n# !wget -P {HOME}/data -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n# !ls -lh {HOME}/data\n!cp -r /kaggle/input/car-plate-detection {HOME}/data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzN8FRtSlemo","outputId":"d339ac37-b02b-4db5-de06-fecbcad1f5de","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference with Pre-trained COCO Model","metadata":{"id":"s5RGYA6sPgEd"}},{"cell_type":"markdown","source":"**NOTE:** YOLOv10 is based on YOLOv8, and like YOLOv8, it can be used in both CLI and SDK modes.","metadata":{"id":"i4Z0cZapszEY"}},{"cell_type":"markdown","source":"### üíª CLI","metadata":{"id":"fT1qD4toTTw0"}},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=predict conf=0.25 save=True \\\nmodel={HOME}/weights/yolov10n.pt \\\nsource={HOME}/datasets/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDbMt_M6PiXb","outputId":"0816a3ff-5384-4bba-8abf-29da8fa89c76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=predict conf=0.25 save=True \\\nmodel={HOME}/weights/yolov10n.pt \\\nsource=/kaggle/input/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NONE:** Let's display result.","metadata":{"id":"ZN9CdBZ2nYRf"}},{"cell_type":"code","source":"%cd {HOME}\n\nfrom IPython.display import Image\n\nImage(filename='runs/detect/predict2/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg', height=600)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"id":"LyopYpK1TQrB","outputId":"769e5dd2-7cb3-47c8-ab5a-027959b6f6e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üêç Python SDK","metadata":{"id":"AFMBYQtMVL-B"}},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nresults = model(source=f'{HOME}/data/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg', conf=0.25)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx9NWF-sVN6Y","outputId":"c7ee4c8b-c236-4719-ec6f-cee6b264ca49","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nresults = model(source=f'/kaggle/input/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg', conf=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results[0].boxes.xyxy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAi4PvrItTCf","outputId":"23f9042c-2bcc-4ca7-e4c3-606093008a7e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results[0].boxes.conf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqT2M01K1LUb","outputId":"7cc3f419-7cd9-4fd0-f073-928e99cd7b20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results[0].boxes.cls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKIwJ5yw1PMb","outputId":"84f1240d-0284-4f02-9f5c-951ed02576e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NONE:** Let's display result using `supervision`.","metadata":{"id":"O26ZKAsindq8"}},{"cell_type":"code","source":"import cv2\nimport supervision as sv\nfrom ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nimage = cv2.imread(f'{HOME}/data/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg')\nresults = model(image)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SaKTSzSWnG7s","outputId":"7b618572-fcfa-4956-83ef-a68ef9982cc7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport supervision as sv\nfrom ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nimage = cv2.imread(f'/kaggle/input/car-plate-detection/test/images/21310932_jpg.rf.a90efe1889d8188d6f3c503fac1666f1.jpg')\nresults = model(image)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:08:47.597612Z","iopub.execute_input":"2024-07-02T17:08:47.597923Z","iopub.status.idle":"2024-07-02T17:08:48.756788Z","shell.execute_reply.started":"2024-07-02T17:08:47.597895Z","shell.execute_reply":"2024-07-02T17:08:48.756023Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\n0: 640x640 2 persons, 4 cars, 1 truck, 13.2ms\nSpeed: 5.4ms preprocess, 13.2ms inference, 154.8ms postprocess per image at shape (1, 3, 640, 640)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download dataset from Roboflow Universe","metadata":{"id":"t8Epf5rhnpV_"}},{"cell_type":"code","source":"!mkdir {HOME}/datasets\n%cd {HOME}/datasets\n\n# !pip install -q roboflow\n\n# from google.colab import userdata\n# from roboflow import Roboflow\n\n# ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n\n# rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n# project = rf.workspace(\"selencakmak\").project(\"tumor-dj2a1\")\n# version = project.version(1)\n# dataset = version.download(\"yolov8\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSd93ZJzZZKt","outputId":"cbce34e5-4a8a-4e69-ade2-ec060f1b0b19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd {HOME}\ndataset = f\"{HOME}/datasets/car-plate-detection\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:**\nMake sure the last 4 lines of the data.yaml file have the following format:\n\n```\ntest: ../test/images\ntrain: ../train/images\nval: ../valid/images\n```\n\nIf using a dataset from Roboflow Universe, run the command below. üëáüèª","metadata":{"id":"yvRoruMguOIZ"}},{"cell_type":"code","source":"!cd {HOME}\n!cp -rf {HOME}/data/car-plate-detection {HOME}/datasets\n!rm -rf {HOME}/data/car-plate-detection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}/datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i '$d' datasets/car-plate-detection/data.yaml\n!sed -i '$d'  datasets/car-plate-detection/data.yaml\n!sed -i '$d'  datasets/car-plate-detection/data.yaml\n!sed -i '$d'  datasets/car-plate-detection/data.yaml\n!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> datasets/car-plate-detection/data.yaml","metadata":{"id":"2LLYQIS0tbC1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Training","metadata":{"id":"YUjFBKKqXa-u"}},{"cell_type":"code","source":"!pip install wandb\nimport wandb\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wdb_token = input(\"Enter the wandb toke: \")\nwandb.login(key=wdb_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=train epochs=10 batch=32 plots=True \\\nmodel={HOME}/weights/yolov10n.pt \\\ndata={HOME}/datasets/car-plate-detection/data.yaml","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2YkphuiaE7_","outputId":"6145b761-5a99-4c8a-d17c-db03baa115b7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=train epochs=50 batch=32 plots=True \\\nmodel={HOME}/runs/detect/train4/weights/best.pt \\\ndata={HOME}/datasets/car-plate-detection/data.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls {HOME}/runs/detect/train/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MScstfHhArr","outputId":"0edc27e0-b305-43a2-f169-4a71f8ced5a6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train4/confusion_matrix.png', width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train5/confusion_matrix.png', width=600)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"_J35i8Ofhjxa","outputId":"46a74b23-e0a4-44be-8976-b06328225251","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train4/results.png', width=600)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"A-urTWUkhRmn","outputId":"bf7af346-5994-45c9-c22f-4fce5a5e8467","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train5/results.png', width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls {HOME}/runs/detect/train5/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference with Custom Model","metadata":{"id":"Sh6h0MOEy2WX"}},{"cell_type":"markdown","source":"**NOTE:** Let's start by loading our newly trained model.","metadata":{"id":"TNjsAO8m08ti"}},{"cell_type":"code","source":"!pwd\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/runs/detect/train4/weights/best.pt')\n\ndataset = sv.DetectionDataset.from_yolo(\n    images_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/images\",\n    annotations_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/labels\",\n    data_yaml_path=f\"{HOME}/datasets/car-plate-detection/data.yaml\"\n)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()","metadata":{"id":"AY1ajwSzyXCE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** Let's randomly select an image from our validation set and visualize the results.","metadata":{"id":"ibNL8dwU1Jqw"}},{"cell_type":"code","source":"import random\n\nrandom_image = random.choice(list(dataset.images.keys()))\nrandom_image = dataset.images[random_image]\n\nresults = model(source=random_image, conf=0.25)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=random_image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"id":"rDuvNsnH0OEV","outputId":"c2445d7b-efb7-4068-f876-6b7289d083e8","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/runs/detect/train5/weights/best.pt')\n\ndataset = sv.DetectionDataset.from_yolo(\n    images_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/images\",\n    annotations_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/labels\",\n    data_yaml_path=f\"{HOME}/datasets/car-plate-detection/data.yaml\"\n)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nrandom_image = random.choice(list(dataset.images.keys()))\nrandom_image = dataset.images[random_image]\n\nresults = model(source=random_image, conf=0.25)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=random_image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nimport easyocr\n\n# Initialize the OCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Mapping dictionaries for character conversion\ndict_char_to_int = {'O': '0',\n                    'I': '1',\n                    'J': '3',\n                    'A': '4',\n                    'G': '6',\n                    'S': '5'}\n\ndict_int_to_char = {'0': 'O',\n                    '1': 'I',\n                    '3': 'J',\n                    '4': 'A',\n                    '6': 'G',\n                    '5': 'S'}\n\n\ndef write_csv(results, output_path):\n    \"\"\"\n    Write the results to a CSV file.\n\n    Args:\n        results (dict): Dictionary containing the results.\n        output_path (str): Path to the output CSV file.\n    \"\"\"\n    with open(output_path, 'w') as f:\n        f.write('{},{},{},{},{},{},{}\\n'.format('frame_nmr', 'car_id', 'car_bbox',\n                                                'license_plate_bbox', 'license_plate_bbox_score', 'license_number',\n                                                'license_number_score'))\n\n        for frame_nmr in results.keys():\n            for car_id in results[frame_nmr].keys():\n                print(results[frame_nmr][car_id])\n                if 'car' in results[frame_nmr][car_id].keys() and \\\n                   'license_plate' in results[frame_nmr][car_id].keys() and \\\n                   'text' in results[frame_nmr][car_id]['license_plate'].keys():\n                    f.write('{},{},{},{},{},{},{}\\n'.format(frame_nmr,\n                                                            car_id,\n                                                            '[{} {} {} {}]'.format(\n                                                                results[frame_nmr][car_id]['car']['bbox'][0],\n                                                                results[frame_nmr][car_id]['car']['bbox'][1],\n                                                                results[frame_nmr][car_id]['car']['bbox'][2],\n                                                                results[frame_nmr][car_id]['car']['bbox'][3]),\n                                                            '[{} {} {} {}]'.format(\n                                                                results[frame_nmr][car_id]['license_plate']['bbox'][0],\n                                                                results[frame_nmr][car_id]['license_plate']['bbox'][1],\n                                                                results[frame_nmr][car_id]['license_plate']['bbox'][2],\n                                                                results[frame_nmr][car_id]['license_plate']['bbox'][3]),\n                                                            results[frame_nmr][car_id]['license_plate']['bbox_score'],\n                                                            results[frame_nmr][car_id]['license_plate']['text'],\n                                                            results[frame_nmr][car_id]['license_plate']['text_score'])\n                            )\n        f.close()\n\n\ndef license_complies_format(text):\n    \"\"\"\n    Check if the license plate text complies with the required format.\n\n    Args:\n        text (str): License plate text.\n\n    Returns:\n        bool: True if the license plate complies with the format, False otherwise.\n    \"\"\"\n    if len(text) != 7:\n        return False\n\n    if (text[0] in string.ascii_uppercase or text[0] in dict_int_to_char.keys()) and \\\n       (text[1] in string.ascii_uppercase or text[1] in dict_int_to_char.keys()) and \\\n       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n        return True\n    else:\n        return False\n\n\ndef format_license(text):\n    \"\"\"\n    Format the license plate text by converting characters using the mapping dictionaries.\n\n    Args:\n        text (str): License plate text.\n\n    Returns:\n        str: Formatted license plate text.\n    \"\"\"\n    license_plate_ = ''\n    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n               2: dict_char_to_int, 3: dict_char_to_int}\n    for j in [0, 1, 2, 3, 4, 5, 6]:\n        if text[j] in mapping[j].keys():\n            license_plate_ += mapping[j][text[j]]\n        else:\n            license_plate_ += text[j]\n\n    return license_plate_\n\n\ndef read_license_plate(license_plate_crop):\n    \"\"\"\n    Read the license plate text from the given cropped image.\n\n    Args:\n        license_plate_crop (PIL.Image.Image): Cropped image containing the license plate.\n\n    Returns:\n        tuple: Tuple containing the formatted license plate text and its confidence score.\n    \"\"\"\n\n    detections = reader.readtext(license_plate_crop)\n\n    for detection in detections:\n        bbox, text, score = detection\n\n        text = text.upper().replace(' ', '')\n\n        if license_complies_format(text):\n            return format_license(text), score\n\n    return None, None\n\n\ndef get_car(license_plate, vehicle_track_ids):\n    \"\"\"\n    Retrieve the vehicle coordinates and ID based on the license plate coordinates.\n\n    Args:\n        license_plate (tuple): Tuple containing the coordinates of the license plate (x1, y1, x2, y2, score, class_id).\n        vehicle_track_ids (list): List of vehicle track IDs and their corresponding coordinates.\n\n    Returns:\n        tuple: Tuple containing the vehicle coordinates (x1, y1, x2, y2) and ID.\n    \"\"\"\n    x1, y1, x2, y2, score, class_id = license_plate\n\n    foundIt = False\n    for j in range(len(vehicle_track_ids)):\n        xcar1, ycar1, xcar2, ycar2, car_id = vehicle_track_ids[j]\n\n        if x1 > xcar1 and y1 > ycar1 and x2 < xcar2 and y2 < ycar2:\n            car_indx = j\n            foundIt = True\n            break\n\n    if foundIt:\n        return vehicle_track_ids[car_indx]\n\n    return -1, -1, -1, -1, -1","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:32:17.755110Z","iopub.execute_input":"2024-07-02T17:32:17.755506Z","iopub.status.idle":"2024-07-02T17:32:20.909420Z","shell.execute_reply.started":"2024-07-02T17:32:17.755474Z","shell.execute_reply":"2024-07-02T17:32:20.908609Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!pip install -q filterpy==1.4.5 scikit-image==0.17.2 lap==0.4.0","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:09:20.484422Z","iopub.execute_input":"2024-07-02T17:09:20.485150Z","iopub.status.idle":"2024-07-02T17:09:32.867413Z","shell.execute_reply.started":"2024-07-02T17:09:20.485114Z","shell.execute_reply":"2024-07-02T17:09:32.866239Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\n\n# import util\nfrom sort.sort import *\n# from util import get_car, read_license_plate, write_csv\n\n\nresults = {}\n\nmot_tracker = Sort()\n\n# load models\ncoco_model =  YOLOv10(f'{HOME}/weights/yolov10n.pt')\nlicense_plate_detector =  YOLOv10(f'{HOME}/runs/detect/train5/weights/best.pt')\n\n# load video\ncap = cv2.VideoCapture('/kaggle/input/sample-video/sample.mp4')\n\nvehicles = [2, 3, 5, 7]\n\n# read frames\nframe_nmr = -1\nret = True\n# should_stop = False\n# gotten_detections = 0\nwhile ret:\n    frame_nmr += 1\n    ret, frame = cap.read()\n    if ret:\n        results[frame_nmr] = {}\n        # detect vehicles\n        detections = coco_model(frame)[0]\n        detections_ = []\n        for detection in detections.boxes.data.tolist():\n            x1, y1, x2, y2, score, class_id = detection\n            if int(class_id) in vehicles:\n                detections_.append([x1, y1, x2, y2, score])\n\n        # track vehicles\n        track_ids = mot_tracker.update(np.asarray(detections_))\n\n        # detect license plates\n        license_plates = license_plate_detector(frame)[0]\n        \n        for license_plate in license_plates.boxes.data.tolist():\n            x1, y1, x2, y2, score, class_id = license_plate\n\n        # assign license plate to car\n#         if class_id==0:\n            xcar1, ycar1, xcar2, ycar2, car_id = get_car(license_plate, track_ids)\n\n            if car_id != -1:\n\n                # crop license plate\n                license_plate_crop = frame[int(y1):int(y2), int(x1): int(x2), :]\n\n                # process license plate\n                license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n                #_, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 64, 255, cv2.THRESH_BINARY_INV)\n\n                # read license plate number\n                license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop_gray)\n\n                if license_plate_text is not None:\n                    gotten_detections += 1\n                    print(\"license_plate_text: \",license_plate_text)\n                    print(\"license_plate_text_score: \",license_plate_text_score)\n                    results[frame_nmr][car_id] = {'car': {'bbox': [xcar1, ycar1, xcar2, ycar2]},\n                                                  'license_plate': {'bbox': [x1, y1, x2, y2],\n                                                                    'text': license_plate_text,\n                                                                    'bbox_score': score,\n                                                                    'text_score': license_plate_text_score}}\n#     if gotten_detections>=20 or frame_nmr>=1000:\n#         print(\"Results: \",results)\n#         break\n\n# write results\nwrite_csv(results, './test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport numpy as np\nfrom scipy.interpolate import interp1d\n\n\ndef interpolate_bounding_boxes(data):\n    # Extract necessary data columns from input data\n    frame_numbers = np.array([int(row['frame_nmr']) for row in data])\n    car_ids = np.array([int(float(row['car_id'])) for row in data])\n    car_bboxes = np.array([list(map(float, row['car_bbox'][1:-1].split())) for row in data])\n    license_plate_bboxes = np.array([list(map(float, row['license_plate_bbox'][1:-1].split())) for row in data])\n\n    interpolated_data = []\n    unique_car_ids = np.unique(car_ids)\n    for car_id in unique_car_ids:\n\n        frame_numbers_ = [p['frame_nmr'] for p in data if int(float(p['car_id'])) == int(float(car_id))]\n        print(frame_numbers_, car_id)\n\n        # Filter data for a specific car ID\n        car_mask = car_ids == car_id\n        car_frame_numbers = frame_numbers[car_mask]\n        car_bboxes_interpolated = []\n        license_plate_bboxes_interpolated = []\n\n        first_frame_number = car_frame_numbers[0]\n        last_frame_number = car_frame_numbers[-1]\n\n        for i in range(len(car_bboxes[car_mask])):\n            frame_number = car_frame_numbers[i]\n            car_bbox = car_bboxes[car_mask][i]\n            license_plate_bbox = license_plate_bboxes[car_mask][i]\n\n            if i > 0:\n                prev_frame_number = car_frame_numbers[i-1]\n                prev_car_bbox = car_bboxes_interpolated[-1]\n                prev_license_plate_bbox = license_plate_bboxes_interpolated[-1]\n\n                if frame_number - prev_frame_number > 1:\n                    # Interpolate missing frames' bounding boxes\n                    frames_gap = frame_number - prev_frame_number\n                    x = np.array([prev_frame_number, frame_number])\n                    x_new = np.linspace(prev_frame_number, frame_number, num=frames_gap, endpoint=False)\n                    interp_func = interp1d(x, np.vstack((prev_car_bbox, car_bbox)), axis=0, kind='linear')\n                    interpolated_car_bboxes = interp_func(x_new)\n                    interp_func = interp1d(x, np.vstack((prev_license_plate_bbox, license_plate_bbox)), axis=0, kind='linear')\n                    interpolated_license_plate_bboxes = interp_func(x_new)\n\n                    car_bboxes_interpolated.extend(interpolated_car_bboxes[1:])\n                    license_plate_bboxes_interpolated.extend(interpolated_license_plate_bboxes[1:])\n\n            car_bboxes_interpolated.append(car_bbox)\n            license_plate_bboxes_interpolated.append(license_plate_bbox)\n\n        for i in range(len(car_bboxes_interpolated)):\n            frame_number = first_frame_number + i\n            row = {}\n            row['frame_nmr'] = str(frame_number)\n            row['car_id'] = str(car_id)\n            row['car_bbox'] = ' '.join(map(str, car_bboxes_interpolated[i]))\n            row['license_plate_bbox'] = ' '.join(map(str, license_plate_bboxes_interpolated[i]))\n\n            if str(frame_number) not in frame_numbers_:\n                # Imputed row, set the following fields to '0'\n                row['license_plate_bbox_score'] = '0'\n                row['license_number'] = '0'\n                row['license_number_score'] = '0'\n            else:\n                # Original row, retrieve values from the input data if available\n                original_row = [p for p in data if int(p['frame_nmr']) == frame_number and int(float(p['car_id'])) == int(float(car_id))][0]\n                row['license_plate_bbox_score'] = original_row['license_plate_bbox_score'] if 'license_plate_bbox_score' in original_row else '0'\n                row['license_number'] = original_row['license_number'] if 'license_number' in original_row else '0'\n                row['license_number_score'] = original_row['license_number_score'] if 'license_number_score' in original_row else '0'\n\n            interpolated_data.append(row)\n\n    return interpolated_data\n\n\n# Load the CSV file\nwith open('test.csv', 'r') as file:\n    reader = csv.DictReader(file)\n    data = list(reader)\n\n# Interpolate missing data\ninterpolated_data = interpolate_bounding_boxes(data)\n\n# Write updated data to a new CSV file\nheader = ['frame_nmr', 'car_id', 'car_bbox', 'license_plate_bbox', 'license_plate_bbox_score', 'license_number', 'license_number_score']\nwith open('test_interpolated.csv', 'w', newline='') as file:\n    writer = csv.DictWriter(file, fieldnames=header)\n    writer.writeheader()\n    writer.writerows(interpolated_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\n\nimport cv2\nimport numpy as np\nimport pandas as pd\n\n\ndef draw_border(img, top_left, bottom_right, color=(0, 255, 0), thickness=10, line_length_x=200, line_length_y=200):\n    x1, y1 = top_left\n    x2, y2 = bottom_right\n\n    cv2.line(img, (x1, y1), (x1, y1 + line_length_y), color, thickness)  #-- top-left\n    cv2.line(img, (x1, y1), (x1 + line_length_x, y1), color, thickness)\n\n    cv2.line(img, (x1, y2), (x1, y2 - line_length_y), color, thickness)  #-- bottom-left\n    cv2.line(img, (x1, y2), (x1 + line_length_x, y2), color, thickness)\n\n    cv2.line(img, (x2, y1), (x2 - line_length_x, y1), color, thickness)  #-- top-right\n    cv2.line(img, (x2, y1), (x2, y1 + line_length_y), color, thickness)\n\n    cv2.line(img, (x2, y2), (x2, y2 - line_length_y), color, thickness)  #-- bottom-right\n    cv2.line(img, (x2, y2), (x2 - line_length_x, y2), color, thickness)\n\n    return img\n\n\nresults = pd.read_csv('./test_interpolated.csv')\n\n# load video\nvideo_path = '/kaggle/input/sample-video/sample.mp4'\ncap = cv2.VideoCapture(video_path)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter('./out.mp4', fourcc, fps, (width, height))\n\nlicense_plate = {}\nfor car_id in np.unique(results['car_id']):\n    max_ = np.amax(results[results['car_id'] == car_id]['license_number_score'])\n    license_plate[car_id] = {'license_crop': None,\n                             'license_plate_number': results[(results['car_id'] == car_id) &\n                                                             (results['license_number_score'] == max_)]['license_number'].iloc[0]}\n    cap.set(cv2.CAP_PROP_POS_FRAMES, results[(results['car_id'] == car_id) &\n                                             (results['license_number_score'] == max_)]['frame_nmr'].iloc[0])\n    ret, frame = cap.read()\n\n    x1, y1, x2, y2 = ast.literal_eval(results[(results['car_id'] == car_id) &\n                                              (results['license_number_score'] == max_)]['license_plate_bbox'].iloc[0].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n\n    license_crop = frame[int(y1):int(y2), int(x1):int(x2), :]\n    license_crop = cv2.resize(license_crop, (int((x2 - x1) * 400 / (y2 - y1)), 400))\n\n    license_plate[car_id]['license_crop'] = license_crop\n\n\nframe_nmr = -1\n\ncap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n\n# read frames\nret = True\nwhile ret:\n    ret, frame = cap.read()\n    frame_nmr += 1\n    if ret:\n        df_ = results[results['frame_nmr'] == frame_nmr]\n        for row_indx in range(len(df_)):\n            # draw car\n            car_x1, car_y1, car_x2, car_y2 = ast.literal_eval(df_.iloc[row_indx]['car_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n            draw_border(frame, (int(car_x1), int(car_y1)), (int(car_x2), int(car_y2)), (0, 255, 0), 25,\n                        line_length_x=200, line_length_y=200)\n\n            # draw license plate\n            x1, y1, x2, y2 = ast.literal_eval(df_.iloc[row_indx]['license_plate_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 12)\n\n            # crop license plate\n            license_crop = license_plate[df_.iloc[row_indx]['car_id']]['license_crop']\n\n            H, W, _ = license_crop.shape\n\n            try:\n                frame[int(car_y1) - H - 100:int(car_y1) - 100,\n                      int((car_x2 + car_x1 - W) / 2):int((car_x2 + car_x1 + W) / 2), :] = license_crop\n\n                frame[int(car_y1) - H - 400:int(car_y1) - H - 100,\n                      int((car_x2 + car_x1 - W) / 2):int((car_x2 + car_x1 + W) / 2), :] = (255, 255, 255)\n\n                (text_width, text_height), _ = cv2.getTextSize(\n                    license_plate[df_.iloc[row_indx]['car_id']]['license_plate_number'],\n                    cv2.FONT_HERSHEY_SIMPLEX,\n                    4.3,\n                    17)\n\n                cv2.putText(frame,\n                            license_plate[df_.iloc[row_indx]['car_id']]['license_plate_number'],\n                            (int((car_x2 + car_x1 - text_width) / 2), int(car_y1 - H - 250 + (text_height / 2))),\n                            cv2.FONT_HERSHEY_SIMPLEX,\n                            4.3,\n                            (0, 0, 0),\n                            17)\n\n            except:\n                pass\n\n        out.write(frame)\n        frame = cv2.resize(frame, (1280, 720))\n\n        # cv2.imshow('frame', frame)\n        # cv2.waitKey(0)\n\nout.release()\ncap.release()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:59:11.068522Z","iopub.execute_input":"2024-07-02T17:59:11.069446Z","iopub.status.idle":"2024-07-02T18:05:18.646009Z","shell.execute_reply.started":"2024-07-02T17:59:11.069406Z","shell.execute_reply":"2024-07-02T18:05:18.644815Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/runs/detect/train5/weights/best.pt')\n\ndataset = sv.DetectionDataset.from_yolo(\n    images_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/images\",\n    annotations_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/labels\",\n    data_yaml_path=f\"{HOME}/datasets/car-plate-detection/data.yaml\"\n)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/runs/detect/train5/weights/best.pt')\n\ndataset = sv.DetectionDataset.from_yolo(\n    images_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/images\",\n    annotations_directory_path=f\"{HOME}/datasets/car-plate-detection/valid/labels\",\n    data_yaml_path=f\"{HOME}/datasets/car-plate-detection/data.yaml\"\n)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"license_plate_detector = YOLOv10(f'{HOME}/runs/detect/train5/weights/best.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom ultralytics import YOLO\nimport cv2\n\n\n\n\n# load video\ncap = cv2.VideoCapture('/kaggle/input/car-plate-detection-video-sample/TEST.mp4')\n\n\n# read frames\nframe_nmr = -1\nret = True\nstop=False\nwhile ret:\n    frame_nmr += 1\n    ret, frame = cap.read()\n    if ret:\n        detections_ = []\n        # detect license plates\n        license_plates = license_plate_detector(frame)[0]\n        for license_plate in license_plates.boxes.data.tolist():\n            x1, y1, x2, y2, score, class_id = license_plate\n            # crop license plate\n            license_plate_crop = frame[int(y1):int(y2), int(x1): int(x2), :]\n\n            # process license plate\n            license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n            sv.plot_image(license_plate_crop_gray)\n            _, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 64, 255, cv2.THRESH_BINARY_INV)\n\n            # read license plate number\n            license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop_thresh)\n            \n            if license_plate_text is not None:\n                print(\"read_license_plate: \")\n                print(\"license_plate_text: \",license_plate_text)\n                print(\"license_plate_text_score: \",license_plate_text_score)\n                stop = True\n        if stop:\n            break\n            \n\n#             if license_plate_text is not None:\n#                 print(license_plate_text)\n#                 break\n#             break\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load video\ncap = cv2.VideoCapture('/kaggle/input/car-plate-detection-video-sample/TEST.mp4')\n\n\n# read frames\nframe_nmr = -1\ndetections_num = 0\nwhile ret:\n    frame_nmr += 1\n    ret, frame = cap.read()\n    results = model(source=frame, conf=0.25)[0]\n    if len(results.boxes.data.tolist())>0:\n        detections = sv.Detections.from_ultralytics(results)\n        annotated_image = bounding_box_annotator.annotate(\n            scene=frame, detections=detections)\n        annotated_image = label_annotator.annotate(\n            scene=annotated_image, detections=detections)\n\n        sv.plot_image(annotated_image)\n        \n        for license_plate in results.boxes.data.tolist():\n            x1, y1, x2, y2, score, class_id = license_plate\n            # crop license plate\n            license_plate_crop = frame[int(y1):int(y2), int(x1): int(x2), :]\n\n            # process license plate\n            license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n            sv.plot_image(license_plate_crop_gray)\n           # _, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 127, 255, cv2.THRESH_TOZERO_INV)\n\n            \n            #print(\"license_plate_crop_thresh: \",license_plate_crop_thresh)\n            # read license plate number\n            license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop)\n            #license_plate_text1, license_plate_text_score1 = read_license_plate(license_plate_crop_thresh)\n#             detections_num += 1\n\n            if license_plate_text is not None:\n                print(\"read_license_plate: \")\n                print(\"license_plate_text: \",license_plate_text)\n                print(\"license_plate_text_score: \",license_plate_text_score)\n#             if license_plate_text1 is not None:\n#                 print(\"read_license_plate: \")\n#                 print(\"license_plate_text1: \",license_plate_text1)\n#                 print(\"license_plate_text_score1: \",license_plate_text_score1)\n                detections_num += 1\n        \n    if detections_num>=20:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport cv2 as cv\n\n\nimages_directory_path=f\"{HOME}/datasets/car-plate-detection/test/images\"\n\n\nfor img in os.listdir(images_directory_path) :\n    test_img_path = os.path.join(images_directory_path, img)\n    test_img = cv2.imread(test_img_path)  # Read the image as an array\n    results = model(source=test_img, conf=0.25)[0]\n\n\n    if len(results.boxes.data.tolist())>0:\n        detections = sv.Detections.from_ultralytics(results)\n        annotated_image = bounding_box_annotator.annotate(\n            scene=test_img, detections=detections)\n        annotated_image = label_annotator.annotate(\n            scene=annotated_image, detections=detections)\n\n        sv.plot_image(annotated_image)\n\n        for license_plate in results.boxes.data.tolist():\n            x1, y1, x2, y2, score, class_id = license_plate\n            if class_id == 0:  # Check if the detected object is a license plate\n                # Crop license plate\n                license_plate_crop = test_img[int(y1):int(y2), int(x1):int(x2)]\n\n                # Process license plate\n                license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n                sv.plot_image(license_plate_crop_gray)\n                _, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 127, 255, cv2.THRESH_TOZERO_INV)\n                th3 = cv.adaptiveThreshold(license_plate_crop_gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n cv.THRESH_BINARY,11,2)\n                sv.plot_image(license_plate_crop_thresh)\n                sv.plot_image(th3)\n                \n\n                # Read license plate number\n                license_plate_text, license_plate_text_score = read_license_plate(th3)\n\n                if license_plate_text is not None:\n                    print(\"read_license_plate: \")\n                    print(\"license_plate_text: \", license_plate_text)\n                    print(\"license_plate_text_score: \", license_plate_text_score)\n        \n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}